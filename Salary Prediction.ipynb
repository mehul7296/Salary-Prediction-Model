{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZ2Xk41qLqU_"
   },
   "source": [
    "# Group work - Assessment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvL515xkLqVA"
   },
   "source": [
    "In this assignment, we will focus on salary prediction. The data set for this assignment includes information on job descriptions and salaries. Use this data set to see if you can predict the salary of a job posting (i.e., the `Salary` column in the data set) based on the job description. This is important, because this model can make a salary recommendation as soon as a job description is entered into a system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-F1sm8sLqVB"
   },
   "source": [
    "## Description of Variables\n",
    "\n",
    "The description of variables are provided in \"Jobs - Data Dictionary.docx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy0eO3eCLqVB"
   },
   "source": [
    "## Goal\n",
    "\n",
    "Use the **jobs_alldata.csv** data set and build models to predict **salary**.\n",
    "\n",
    "**Be careful: this is a REGRESSION task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzRXokcpLqVB"
   },
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "837-6_t0LqVB"
   },
   "source": [
    "## Recommended roles for group members:\n",
    "\n",
    "**Section 1:** to be completed by both group members\n",
    "\n",
    "**Section 2:** first three models to be completed by the first group member and checked by the second; last two models to be completed by the second group members and checked by the first group member.\n",
    "\n",
    "**Discussion:** to be completed by both group members\n",
    "\n",
    "**Important notes:**\n",
    "- Both group members will get the same grade. Therefore, you should check the work of your group member. If they make a mistake, you will be responsible for that mistake too.\n",
    "- Both group members must put in their fair share of effort. Otherwise, those who don't contribute to the assignment will not receive any grade.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFqC7qlwLqVC"
   },
   "source": [
    "# Section 1: (8 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uCE_6mOLqVC"
   },
   "source": [
    "## Data Prep (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\manis\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorflow) (3.20.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\manis\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\manis\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\manis\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "! Pip install tensorflow\n",
    "! Pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eJIP1cuyLqVC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "XcDVFRzQLqVD",
    "outputId": "b86e9353-e473-44aa-c146-1682709e857d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Civil Service Title: Regional Director Mental ...</td>\n",
       "      <td>67206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The New York City Comptrollerâ€™s Office Burea...</td>\n",
       "      <td>88313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With minimal supervision from the Deputy Commi...</td>\n",
       "      <td>81315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPEN TO CURRENT BUSINESS PROMOTION COORDINATOR...</td>\n",
       "      <td>76426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only candidates who are permanent in the Princ...</td>\n",
       "      <td>55675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Description  Salary\n",
       "0  Civil Service Title: Regional Director Mental ...   67206\n",
       "1  The New York City Comptrollerâ€™s Office Burea...   88313\n",
       "2  With minimal supervision from the Deputy Commi...   81315\n",
       "3  OPEN TO CURRENT BUSINESS PROMOTION COORDINATOR...   76426\n",
       "4  Only candidates who are permanent in the Princ...   55675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAs in data: Job Description    0\n",
      "Salary             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>77990.330294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29202.739636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>72689.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90518.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>224351.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Salary\n",
       "count    2413.000000\n",
       "mean    77990.330294\n",
       "std     29202.739636\n",
       "min      3624.000000\n",
       "25%     58064.000000\n",
       "50%     72689.000000\n",
       "75%     90518.000000\n",
       "max    224351.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('jobs_alldata.csv')[['Job Description', 'Salary']]\n",
    "display(data_df.head())\n",
    "\n",
    "print('NAs in data:',data_df.isna().sum())\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "5bDIineZLqVE",
    "outputId": "75749e0e-8946-4e13-d1bc-979593b5d026"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Civil Service Title: Regional Director Mental Health Services, M-2  Full Time; Evenings and Weekends as needed  New York City Department of Health and Mental Hygiene, Division of Mental Hygiene seeks one fulltime Executive Director for the Co-Response/Heat Program. The unit employs law enforcement, clinical and non-clinical professionals to engage and support individuals with mental health issues, substance use, co-occurring disorders and health issues who can benefit from short-term engagement, support and linkage to services in the promotion of better health and criminal justice outcomes.   Program Background:   The Unit is comprised of three primary components:   -\\tTriage Desk: act as Teamâ€™s â€œair traffic control,â€\\x9d receiving and processing all incoming referrals to determine the most appropriate response, and provide clinical consultation to members of the force.   -\\tCo-Response team: Clinician and NYPD officer teams conducting community deployments.   -\\tHealth Engagement and Assessment Teams (HEAT), health-only teams working with people identified by the community and first responders, with mental health and substance use who may benefit from short term engagement and support.    Note: All staff traveling in NYPD patrol vehicles are required to wear bullet resistant vests.      The ideal candidate will be:  -\\tPassionate about social justice & health equity  -\\tCommitted to building a diverse and inclusive culture with law enforcement, city agencies and other social service partners    The Executive Director, reporting directly to the Special Advisor on Criminal Justice, is primarily responsible for leadership and management of all Program operations, overseeing all policy, budgetary, programming and personnel matters. The Executive Director will:  -\\tProvide overall program leadership and oversight.     -\\tSupervise all members of the leadership team: Director of Operations, Clinical Director, and Director of Monitoring and Evaluation.  -\\tMonitor the Unitâ€™s clinical practices, protocols and overall supervision structure.   -\\tDevelop and operationalize the Unitâ€™s strategic plan, including long & short term goals.  -\\tLead the HEAT Advisory Group, and represent the program to Senior Health Department staff, City Hall, Sr. NYPD staff, Other City Agencies, OMB and other external parties.  -\\tOversee programâ€™s fiscal, personnel and programmatic matters.  -\\tManage related press issues, in coordination with DOHMH Press office.   -\\tManage inter-governmental  matters, under direction of DOHMH Office of External Affairs.      -\\tOversee and manage overall programmatic performance measures and develop corrective action plan to address issues and challenges as needed.  -\\tOther duties, as assigned.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = data_df['Job Description'].to_numpy()\n",
    "input_text = input_text.astype(str)\n",
    "input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DCuF1vyuLqVE"
   },
   "outputs": [],
   "source": [
    "x = input_text\n",
    "y = data_df['Salary'].to_numpy().astype(int)\n",
    "\n",
    "## Removing outliers in salary variable: Less than 0.01 percentile of salary\n",
    "min_quant = np.quantile(y, 0.01)\n",
    "# max_quant = np.quantile(y, 0.99)\n",
    "# inds = np.where((y >= min_quant) & (y <= max_quant))[0]\n",
    "inds = np.where((y >= min_quant))[0]\n",
    "y = y[inds]\n",
    "x = x[inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaIKlHqlLqVE"
   },
   "source": [
    "## Feature Engineering (1 points)\n",
    "\n",
    "Create one NEW feature from existing data. You either transform a single variable, or create a new variable from existing ones. \n",
    "\n",
    "Grading: \n",
    "- 0.5 points for creating the new feature correctly\n",
    "- 0.5 points for the justification of the new feature (i.e., why did you create this new feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jf1HCD1LqVE",
    "outputId": "ee1802f7-8b29-431c-b040-f174eb0c494f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%Variance retained after PCA: 91.57\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF VECTORIZATION\n",
    "# The reason we created this new feature is most of the ML algorithms can't process the raw strings directly.\n",
    "#so we have to convert the string into vector representation.Tf-idf is one such method .\n",
    "# TF-IDF uses both aspects : The individual frequencies of words  and the context of each term in the whole document.\n",
    "#TF (Term frequency), the count of the word occurring in a document and IDF (inverse document frequency), \n",
    "#the weight component that gives higher importance to words occurring in lesser documents and lower importance to more common words.\n",
    "from sklearn import decomposition\n",
    "import sklearn.utils.sparsefuncs\n",
    "\n",
    "# Transforming words to vector embeddings using tf-idf\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', strip_accents='unicode')\n",
    "tf_idf_x = tfidf_vect.fit_transform(x)\n",
    "tf_idf_x1 = tf_idf_x\n",
    "\n",
    "#Limiting features to 750 by retaining 90% variance in data\n",
    "pca = decomposition.TruncatedSVD(n_components=750)\n",
    "tf_idf_x = pca.fit_transform(tf_idf_x)\n",
    "\n",
    "# Calculating variance after PCA\n",
    "exp = np.var(tf_idf_x, axis=0)\n",
    "full = sklearn.utils.sparsefuncs.mean_variance_axis(tf_idf_x1, axis = 0)[1].sum()\n",
    "explained_variance_ratios = exp / full\n",
    "confidence = sum(explained_variance_ratios)\n",
    "print('%Variance retained after PCA:',round(confidence*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AVtxWRnaLqVE"
   },
   "outputs": [],
   "source": [
    "# NORMALIZING TARGET VALUES\n",
    "y_norm = (y - min(y)) / (max(y) - min(y))\n",
    "\n",
    "# Train, Validation Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(tf_idf_x, y_norm, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUixA-t6LqVE"
   },
   "source": [
    "## Find the Baseline (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-q9Zsjgs8adR",
    "outputId": "bcab794c-602d-4fa9-f2da-0badd9835222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 27552.34\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_value = np.mean(y_train)\n",
    "baseline_pred = np.repeat(mean_value, len(y_test))\n",
    "\n",
    "baseline_pred_rescaled = baseline_pred * (max(y) - min(y)) + min(y)\n",
    "y_test_rescaled = y_test * (max(y) - min(y)) + min(y)\n",
    "\n",
    "print('Baseline RMSE:', round(np.sqrt(sklearn.metrics.mean_squared_error(y_test_rescaled, baseline_pred_rescaled)),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKSZefeXLqVF"
   },
   "source": [
    "# Section 2: (7 points in total)\n",
    "\n",
    "Build the following models:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hr2wQ-FLqVF"
   },
   "source": [
    "## Decision Tree: (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsTA6guwLqVF",
    "outputId": "bc4a7eda-74f0-46d9-8387-5ef4f999e8f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 20718.23\n",
      "Test RMSE: 24427.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor(min_samples_leaf = 10, max_depth=5, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "train_preds = regressor.predict(x_train)\n",
    "train_preds_rescaled = train_preds * (max(y) - min(y)) + min(y)\n",
    "y_train_rescaled = y_train * (max(y) - min(y)) + min(y)\n",
    "dtr_train_rmse = round(np.sqrt(sklearn.metrics.mean_squared_error(y_train_rescaled, train_preds_rescaled)),2)\n",
    "print('Train RMSE:', dtr_train_rmse)\n",
    "\n",
    "test_preds = regressor.predict(x_test)\n",
    "test_preds_rescaled = test_preds * (max(y) - min(y)) + min(y)\n",
    "y_test_rescaled = y_test * (max(y) - min(y)) + min(y)\n",
    "dtr_test_rmse = round(np.sqrt(sklearn.metrics.mean_squared_error(y_test_rescaled, test_preds_rescaled)),2)\n",
    "print('Test RMSE:', dtr_test_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRc1Z-DLLqVF"
   },
   "source": [
    "## Voting regressor (2 points):\n",
    "\n",
    "The voting regressor should have at least 3 individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96X9WJUULqVF",
    "outputId": "6b5b5db3-bc8f-4816-e4d5-0271c97d2e08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 5742.57\n",
      "Test RMSE: 15372.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg1 = DecisionTreeRegressor(random_state=0)\n",
    "reg2 = XGBRegressor()\n",
    "reg3 = RandomForestRegressor(random_state=1)\n",
    "reg4 = LinearRegression()\n",
    "er = VotingRegressor([('rf', reg3), ('dt',reg1), ('lr', reg4)])\n",
    "er.fit(x_train, y_train)\n",
    "\n",
    "train_preds = er.predict(x_train)\n",
    "train_preds_rescaled = train_preds * (max(y) - min(y)) + min(y)\n",
    "y_train_rescaled = y_train * (max(y) - min(y)) + min(y)\n",
    "vr_train_rmse = round(np.sqrt(sklearn.metrics.mean_squared_error(y_train_rescaled, train_preds_rescaled)),2)\n",
    "print('Train RMSE:', vr_train_rmse)\n",
    "\n",
    "test_preds = er.predict(x_test)\n",
    "test_preds_rescaled = test_preds * (max(y) - min(y)) + min(y)\n",
    "y_test_rescaled = y_test * (max(y) - min(y)) + min(y)\n",
    "vr_test_rmse = round(np.sqrt(sklearn.metrics.mean_squared_error(y_test_rescaled, test_preds_rescaled)),2)\n",
    "print('Test RMSE:', vr_test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ug1LuYWzLqVF"
   },
   "source": [
    "## A Boosting model: (1 point)\n",
    "\n",
    "Build either an Adaboost or a GradientBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07DSUvcnLqVF",
    "outputId": "48722a6a-e921-451c-a20a-4fa4fa1626b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1558.34\n",
      "Test RMSE: 14528.65\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "xgb_regressor = XGBRegressor()\n",
    "xgb_regressor.fit(X=x_train, y=y_train)\n",
    "\n",
    "#Train RMSE\n",
    "train_preds = xgb_regressor.predict(x_train)\n",
    "train_preds_rescaled = train_preds * (max(y) - min(y)) + min(y)\n",
    "y_train_rescaled = y_train * (max(y) - min(y)) + min(y)\n",
    "xgbr_train_rmse = round(np.sqrt(sklearn.metrics.mean_squared_error(y_train_rescaled, train_preds_rescaled)),2)\n",
    "print('Train RMSE:', xgbr_train_rmse)\n",
    "\n",
    "#Test RMSE\n",
    "test_preds = xgb_regressor.predict(x_test)\n",
    "test_preds_rescaled = test_preds * (max(y) - min(y)) + min(y)\n",
    "y_test_rescaled = y_test * (max(y) - min(y)) + min(y)\n",
    "xgbr_test_rmse = round(np.sqrt(sklearn.metrics.mean_squared_error(y_test_rescaled, test_preds_rescaled)),2)\n",
    "print('Test RMSE:', xgbr_test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOPK0PJfLqVF"
   },
   "source": [
    "## Neural network: (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3jg5xbO9Fv9",
    "outputId": "5ee5b48d-b667-4293-81b9-5492bc988988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 7218.91\n",
      "Test RMSE: 15199.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50),\n",
    "                       max_iter=1000,\n",
    "                       early_stopping=True,\n",
    "                       alpha = 0.001\n",
    "                     )\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Train RMSE\n",
    "train_pred = model.predict(x_train)\n",
    "train_preds_rescaled = train_pred * (max(y) - min(y)) + min(y)\n",
    "y_train_rescaled = y_train * (max(y) - min(y)) + min(y)\n",
    "train_mse = mean_squared_error(y_train_rescaled, train_preds_rescaled)\n",
    "nn_train_rmse = round(np.sqrt(train_mse), 2)\n",
    "\n",
    "print('Train RMSE: {}' .format(nn_train_rmse))\n",
    "\n",
    "#Test RMSE\n",
    "test_pred = model.predict(x_test)\n",
    "preds_rescaled = test_pred * (max(y) - min(y)) + min(y)\n",
    "y_test_rescaled = y_test * (max(y) - min(y)) + min(y)\n",
    "test_mse = mean_squared_error(y_test_rescaled, preds_rescaled)\n",
    "nn_test_rmse = round(np.sqrt(test_mse), 2)\n",
    "print('Test RMSE: {}' .format(nn_test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZebu9jtLqVG"
   },
   "source": [
    "## Grid search (2 points)\n",
    "\n",
    "Perform either a full or randomized grid search on any model you want. There has to be at least two parameters for the search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4N_Ox8zi4eUr",
    "outputId": "0b787109-2039-4969-f072-54781c220613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 11343.88\n",
      "Test RMSE: 16106.29\n"
     ]
    }
   ],
   "source": [
    "model2 = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50),\n",
    "                       max_iter=1000,\n",
    "                       early_stopping=True,\n",
    "                       alpha = 0.001\n",
    "                     )\n",
    "\n",
    "nn_params ={\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.05],\n",
    "    'hidden0__units': [25, 50, 100],\n",
    "    'hidden1__units': [25, 50, 100],\n",
    "    'hidden2__units': [25, 50, 100],\n",
    "    'hidden3__units': [25, 50, 100],\n",
    "    'hidden4__units': [25, 50, 100]}\n",
    "model2.fit(x_train, y_train)\n",
    "\n",
    "#Train RMSE\n",
    "train_pred = model2.predict(x_train)\n",
    "train_preds_rescaled = train_pred * (max(y) - min(y)) + min(y)\n",
    "y_train_rescaled = y_train * (max(y) - min(y)) + min(y)\n",
    "train_mse = mean_squared_error(y_train_rescaled, train_preds_rescaled)\n",
    "grid_search_nn_train_rmse = round(np.sqrt(train_mse), 2)\n",
    "print('Train RMSE: {}' .format(grid_search_nn_train_rmse))\n",
    "\n",
    "#Test RMSE\n",
    "test_pred = model2.predict(x_test)\n",
    "preds_rescaled = test_pred * (max(y) - min(y)) + min(y)\n",
    "y_test_rescaled = y_test * (max(y) - min(y)) + min(y)\n",
    "test_mse = mean_squared_error(y_test_rescaled, preds_rescaled)\n",
    "grid_search_nn_test_rmse = round(np.sqrt(test_mse), 2)\n",
    "print('Test RMSE: {}' .format(grid_search_nn_test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awQGa8ugLqVG"
   },
   "source": [
    "# Discussion (5 points in total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxoFCEKMLqVG"
   },
   "source": [
    "## List the train and test values of each model you built (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVf4ovxr4eUs",
    "outputId": "7a158f6c-f7bb-4751-8913-09c7d6e3d58d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train rmse:  20718.23 \t\t\t Decision tree test rmse:  24427.48\n",
      "Voting regressor train rmse: 5742.57 \t\t\t Voting regressor test rmse: 15372.86\n",
      "XGBoost train rmse:  1558.34 \t\t\t\t XGBoost test rmse:  14528.65\n",
      "Neural Network train rmse:  7218.91 \t\t\t Neural Network test rmse:  15199.39\n",
      "Grid search Neural Network train rmse:  11343.88 \t Grid search Neural Network test rmse:  16106.29\n"
     ]
    }
   ],
   "source": [
    "print('Decision tree train rmse: ', dtr_train_rmse, '\\t\\t\\t', 'Decision tree test rmse: ', dtr_test_rmse)\n",
    "print('Voting regressor train rmse:', vr_train_rmse, '\\t\\t\\t', 'Voting regressor test rmse:', vr_test_rmse)\n",
    "print('XGBoost train rmse: ', xgbr_train_rmse, '\\t\\t\\t\\t', 'XGBoost test rmse: ', xgbr_test_rmse)\n",
    "print('Neural Network train rmse: ', round(nn_train_rmse, 2), '\\t\\t\\t', 'Neural Network test rmse: ', round(nn_test_rmse, 2))\n",
    "print('Grid search Neural Network train rmse: ', round(grid_search_nn_train_rmse, 2), '\\t', 'Grid search Neural Network test rmse: ', round(grid_search_nn_test_rmse, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJUnIS0KLqVG"
   },
   "source": [
    "## Which model performs the best and why? (0.5 points) \n",
    "## How does it compare to baseline? (0.5 points)\n",
    "\n",
    "Hint: The best model is the one that has the highest TEST score (regardless of any of the training values). If you select your model based on TRAIN values, you will lose points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "mHTge4NLLqVG"
   },
   "source": [
    "XGBoost and Neural Network performs comparably similar as their test RMSE values are smaller than other models. However, by considering test RMSE XGBoost regressor would give less error while making salary predictions. The best model would give much more accurate predictions of salary compared to baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "208WHL-pLqVG"
   },
   "source": [
    "## Is there any evidence of overfitting in the best model, why or why not? If there is, what did you do about it? (1 point)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "DtBl3Dl4LqVG"
   },
   "source": [
    "There is a small possibility of overfitting with XGBoost model. Although, Train RMSE is much smaller than test RMSE but it is in comparable magnitude of salary variable. To avoid overfitting precautions were taken by removing outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1p-lnOaLqVG"
   },
   "source": [
    "## Is there any overfitting in the other models (besides the best model), why or why not? If there is, what did you do about it? (1 point)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Z-Qvc_RVLqVG"
   },
   "source": [
    "There is no evidence of overfitting in other models. Although, Train RMSE values  are smaller than test RMSE but it is in comparable magnitude of salary variable. To avoid overfitting precautions were taken: Removing outliers, grid search with different learning parameters"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Salary_Proj_Fianlv2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
